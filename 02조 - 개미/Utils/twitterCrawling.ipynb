{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed514e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Twitter Data Stream######################################\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "#Define variables below\n",
    "path=\"./data\" #folder where the data will be saved\n",
    "start_date=\"2020-11-01\" #first day for extracting tweets\n",
    "last_date=\"2022-05-02\" #last day (included) for extracting tweets\n",
    "\n",
    "search_word=[\n",
    "[\"PLTR\",\"palantir\",\"2020-11-01\"],\n",
    "[\"TSLA\",\"Tesla\",\"2010-07-02\"],\n",
    "[\"CPNG\", \"Coupang\", \"2021-03-12\"],\n",
    "[\"RBLX\", \"Roblox\", \"2021-03-12\"],\n",
    "[\"RIVN\", \"Rivian\", \"2021-11-12\"],\n",
    "[\"GME\", \"GameStop\", \"2010-05-01\"],\n",
    "[\"NKLA\", \"Nikola\", \"2018-06-13\"],\n",
    "[\"ROKU\", \"ROKU\", \"2017-09-29\"],\n",
    "[\"TDOC\",\"Teladoc\", \"2015-07-02\"]\n",
    "             ]\n",
    "\n",
    "\n",
    "from Scweet.scweet import scrape\n",
    "from Scweet.user import get_user_information, get_users_following, get_users_followers\n",
    "\n",
    "\n",
    "######## Get Tweets######################################\n",
    "\n",
    "#search for each word in search list separately\n",
    "for stock_code,stock_name,start_date in search_word:\n",
    "    print(\"Current search word: \",\"$\"+stock_code,\"%23\"+stock_code,stock_name,start_date)\n",
    "\n",
    "    #search for each date separately\n",
    "    for date_since in pd.date_range(start=start_date,end=last_date):\n",
    "\n",
    "        tweets = scrape(words=[\"$\"+stock_code,\"%23\"+stock_code,stock_name], since=date_since.strftime('%Y-%m-%d'), until=(date_since+dt.timedelta(days=1)).strftime('%Y-%m-%d'),\n",
    "                       from_account = None, interval=1, \n",
    "              headless=True, display_type=\"Top\", save_images=False, \n",
    "              resume=False, filter_replies=True, proximity=False,geocode=\"38.0000,-97.0000,2500km\",lang=\"en\")\n",
    "        \n",
    "        #put content of object into list\n",
    "        tweets=tweets[[\"UserScreenName\",\"Embedded_text\",\"Timestamp\",\"Comments\", \"Likes\", \"Retweets\",]]\n",
    "        tweets.columns = ['user',\"text\",\"date\",\"comments\",\"likes\",\"retweets\"]\n",
    "        tweets.insert(0,\"search_word\",stock_name)\n",
    "\n",
    "\n",
    "        #save daily results\n",
    "        df=tweets\n",
    "        df.to_csv(path+stock_name+\"_\"+date_since.strftime('%Y-%m-%d')+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd22e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9025820792687d1c0da7b36e0715d77bd799d253179141298c77d4d0bf6c43dc"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('recommend_stock_37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
