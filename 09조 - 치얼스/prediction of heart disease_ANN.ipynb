{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689efe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6d4d762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HeartDisease', 'BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
       "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
       "       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
       "       'Asthma', 'KidneyDisease', 'SkinCancer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/JinnyeongHeo/Desktop/2022-1/추천시스템/HeartDisease/archive (1)/heart_2020_cleaned.csv')\n",
    "df.head(5)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b268265",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358d63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe6b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    " \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    " \n",
    "# Encode labels in column 'species'.\n",
    "df['HeartDisease']= label_encoder.fit_transform(df['HeartDisease'])\n",
    "df['Smoking']= label_encoder.fit_transform(df['Smoking'])\n",
    "df['AlcoholDrinking']= label_encoder.fit_transform(df['AlcoholDrinking'])\n",
    "df['Stroke']= label_encoder.fit_transform(df['Stroke'])\n",
    "df['DiffWalking']= label_encoder.fit_transform(df['DiffWalking'])\n",
    "df['Sex']= label_encoder.fit_transform(df['Sex'])\n",
    "df['AgeCategory']= label_encoder.fit_transform(df['AgeCategory'])\n",
    "df['Race']= label_encoder.fit_transform(df['Race'])\n",
    "df['Diabetic']= label_encoder.fit_transform(df['Diabetic'])\n",
    "df['PhysicalActivity']= label_encoder.fit_transform(df['PhysicalActivity'])\n",
    "df['GenHealth']= label_encoder.fit_transform(df['GenHealth'])\n",
    "df['Asthma']= label_encoder.fit_transform(df['Asthma'])\n",
    "df['KidneyDisease']= label_encoder.fit_transform(df['KidneyDisease'])\n",
    "df['SkinCancer']= label_encoder.fit_transform(df['SkinCancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2583fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df\n",
    "\n",
    "df_hd_y = df[df['HeartDisease']==1]\n",
    "\n",
    "df_hd_n = df[df['HeartDisease']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf36a428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((319795, 17), (319795,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = df_cleaned.drop(['HeartDisease'], axis=1)\n",
    "label_data = df_cleaned.HeartDisease.values\n",
    "\n",
    "input_data_hdy = df_hd_y.drop(['HeartDisease'], axis=1)\n",
    "label_data_hdy = df_hd_y.HeartDisease.values\n",
    "\n",
    "input_data_hdn = df_hd_n.drop(['HeartDisease'], axis=1)\n",
    "label_data_hdn = df_hd_n.HeartDisease.values\n",
    "\n",
    "input_data.shape, label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5db4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((319795, 17), (319795,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_np = input_data.to_numpy()\n",
    "label_np = label_data\n",
    "\n",
    "input_np.shape, label_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3199ae46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223856, 95939)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "input_tensor = torch.from_numpy(input_np.astype(np.float32))\n",
    "label_tensor = torch.from_numpy(label_np.astype(np.int64))\n",
    "\n",
    "dataset = TensorDataset(input_tensor, label_tensor)\n",
    "\n",
    "train_len = int(len(dataset) * 0.7)\n",
    "test_len = int(len(dataset) - train_len)\n",
    "\n",
    "\n",
    "(train_len, test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0df624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dataset, [train_len, test_len])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, num_workers=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91457af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([64, 17]) type: torch.FloatTensor\n",
      "y_train: torch.Size([64]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4560cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(17,17)\n",
    "        self.fc2 = nn.Linear(17,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #1\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #2\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #3\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #4\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #5\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #6\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #7\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #8\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #9\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #10\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #11\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #12\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        \n",
    "        ...\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdca10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_bn_do(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model_bn_do, self).__init__()\n",
    "        self.fc1 = nn.Linear(17,17)\n",
    "        self.fc2 = nn.Linear(17,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.8)\n",
    "        self.bn1 = nn.BatchNorm1d(17)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #1\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #2\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #3\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #4\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #5\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #6\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #7\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #8\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #9\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #10\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #11\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #12\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b6d8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(): \n",
    "    path = \"C:/Users/JinnyeongHeo/Desktop/2022-1/추천시스템/HeartDisease_model/NetModel.pth\" \n",
    "    torch.save(network.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9410b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0109dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(train_loader, network, loss_func, optimizer, epoch):\n",
    "    train_losses = []\n",
    "    train_correct = 0\n",
    "    log_interval = 500\n",
    "    \n",
    "    for batch_idx, (inputs, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_size = inputs.size()[0]\n",
    "        inputs = inputs.view(-1, 17)\n",
    "\n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        loss = loss_func(outputs, label)\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        pred = torch.max(outputs,1)[1]\n",
    "        train_correct += pred.eq(label).sum()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'\n",
    "                  .format(epoch, batch_idx * len(label), len(train_loader.dataset),100. * batch_idx / len(train_loader),\n",
    "                          loss.item()))\n",
    "            \n",
    "    return train_losses, train_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6add6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(test_loader, network, loss_func):\n",
    "    correct = 0\n",
    "    \n",
    "    test_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, label) in enumerate(test_loader):\n",
    "            batch_size = inputs.size()[0]\n",
    "            inputs = inputs.view(-1, 17)\n",
    "\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            loss = loss_func(outputs, label)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            pred = torch.max(outputs,1)[1]\n",
    "            correct += pred.eq(label).sum()\n",
    "\n",
    "        test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "        print('Test set: Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
    "    return test_losses, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b288b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def practice_exercise(inputs, network):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs = network(inputs)\n",
    "        \n",
    "        softmax_f = nn.Softmax(dim=1)\n",
    "        \n",
    "        pred_hd = softmax_f(outputs)\n",
    "            \n",
    "        print(pred_hd)\n",
    "            \n",
    "    return pred_hd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d31f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(network, learning_rate = 0.0519):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    epoches = 10\n",
    "    \n",
    "    cls_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(network.parameters(), lr = learning_rate)\n",
    "    \n",
    "    train_losses_per_epoch = []\n",
    "    test_losses_per_epoch = []\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(epoches):\n",
    "                \n",
    "        network.train()\n",
    "        \n",
    "        train_losses, train_correct = training_epoch(train_loader,network,cls_loss,optimizer, epoch)\n",
    "        \n",
    "        average_loss = np.mean(train_losses)\n",
    "        train_losses_per_epoch.append(average_loss)\n",
    "        \n",
    "        train_accuracy = train_correct / len(train_loader.dataset) * 100\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        print('\\nTraining set: Accuracy: {}/{} ({:.0f}%)'\n",
    "              .format(train_correct, len(train_loader.dataset),100. * train_correct / len(train_loader.dataset)))\n",
    "\n",
    "        \n",
    "        network.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            test_losses, test_accuracy = test_epoch(test_loader, network, cls_loss)\n",
    "\n",
    "        test_losses_per_epoch.append(np.mean(test_losses))\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        if test_accuracy > best_accuracy: \n",
    "            saveModel() \n",
    "            best_accuracy = test_accuracy\n",
    "        \n",
    "    return train_losses_per_epoch, test_losses_per_epoch, train_accuracies, test_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6832494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/223856 (0%)]\tLoss: 0.662906\n",
      "Train Epoch: 0 [32000/223856 (14%)]\tLoss: 0.200548\n",
      "Train Epoch: 0 [64000/223856 (29%)]\tLoss: 0.387938\n",
      "Train Epoch: 0 [96000/223856 (43%)]\tLoss: 0.311434\n",
      "Train Epoch: 0 [128000/223856 (57%)]\tLoss: 0.274645\n",
      "Train Epoch: 0 [160000/223856 (71%)]\tLoss: 0.236688\n",
      "Train Epoch: 0 [192000/223856 (86%)]\tLoss: 0.199064\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 1 [0/223856 (0%)]\tLoss: 0.311008\n",
      "Train Epoch: 1 [32000/223856 (14%)]\tLoss: 0.385669\n",
      "Train Epoch: 1 [64000/223856 (29%)]\tLoss: 0.348817\n",
      "Train Epoch: 1 [96000/223856 (43%)]\tLoss: 0.274177\n",
      "Train Epoch: 1 [128000/223856 (57%)]\tLoss: 0.222448\n",
      "Train Epoch: 1 [160000/223856 (71%)]\tLoss: 0.285952\n",
      "Train Epoch: 1 [192000/223856 (86%)]\tLoss: 0.383036\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/223856 (0%)]\tLoss: 0.219470\n",
      "Train Epoch: 2 [32000/223856 (14%)]\tLoss: 0.243935\n",
      "Train Epoch: 2 [64000/223856 (29%)]\tLoss: 0.202300\n",
      "Train Epoch: 2 [96000/223856 (43%)]\tLoss: 0.414497\n",
      "Train Epoch: 2 [128000/223856 (57%)]\tLoss: 0.227741\n",
      "Train Epoch: 2 [160000/223856 (71%)]\tLoss: 0.339785\n",
      "Train Epoch: 2 [192000/223856 (86%)]\tLoss: 0.208450\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/223856 (0%)]\tLoss: 0.165389\n",
      "Train Epoch: 3 [32000/223856 (14%)]\tLoss: 0.183029\n",
      "Train Epoch: 3 [64000/223856 (29%)]\tLoss: 0.250603\n",
      "Train Epoch: 3 [96000/223856 (43%)]\tLoss: 0.165782\n",
      "Train Epoch: 3 [128000/223856 (57%)]\tLoss: 0.195135\n",
      "Train Epoch: 3 [160000/223856 (71%)]\tLoss: 0.261283\n",
      "Train Epoch: 3 [192000/223856 (86%)]\tLoss: 0.216585\n",
      "\n",
      "Training set: Accuracy: 204666/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 4 [0/223856 (0%)]\tLoss: 0.236606\n",
      "Train Epoch: 4 [32000/223856 (14%)]\tLoss: 0.275193\n",
      "Train Epoch: 4 [64000/223856 (29%)]\tLoss: 0.274992\n",
      "Train Epoch: 4 [96000/223856 (43%)]\tLoss: 0.297058\n",
      "Train Epoch: 4 [128000/223856 (57%)]\tLoss: 0.247743\n",
      "Train Epoch: 4 [160000/223856 (71%)]\tLoss: 0.255112\n",
      "Train Epoch: 4 [192000/223856 (86%)]\tLoss: 0.400712\n",
      "\n",
      "Training set: Accuracy: 204670/223856 (91%)\n",
      "Test set: Accuracy: 87672/95939 (91%)\n",
      "\n",
      "Train Epoch: 5 [0/223856 (0%)]\tLoss: 0.308854\n",
      "Train Epoch: 5 [32000/223856 (14%)]\tLoss: 0.194199\n",
      "Train Epoch: 5 [64000/223856 (29%)]\tLoss: 0.226475\n",
      "Train Epoch: 5 [96000/223856 (43%)]\tLoss: 0.195563\n",
      "Train Epoch: 5 [128000/223856 (57%)]\tLoss: 0.268303\n",
      "Train Epoch: 5 [160000/223856 (71%)]\tLoss: 0.228615\n",
      "Train Epoch: 5 [192000/223856 (86%)]\tLoss: 0.155841\n",
      "\n",
      "Training set: Accuracy: 204662/223856 (91%)\n",
      "Test set: Accuracy: 87754/95939 (91%)\n",
      "\n",
      "Train Epoch: 6 [0/223856 (0%)]\tLoss: 0.259519\n",
      "Train Epoch: 6 [32000/223856 (14%)]\tLoss: 0.203908\n",
      "Train Epoch: 6 [64000/223856 (29%)]\tLoss: 0.196485\n",
      "Train Epoch: 6 [96000/223856 (43%)]\tLoss: 0.330086\n",
      "Train Epoch: 6 [128000/223856 (57%)]\tLoss: 0.356237\n",
      "Train Epoch: 6 [160000/223856 (71%)]\tLoss: 0.227621\n",
      "Train Epoch: 6 [192000/223856 (86%)]\tLoss: 0.232473\n",
      "\n",
      "Training set: Accuracy: 204666/223856 (91%)\n",
      "Test set: Accuracy: 87757/95939 (91%)\n",
      "\n",
      "Train Epoch: 7 [0/223856 (0%)]\tLoss: 0.225953\n",
      "Train Epoch: 7 [32000/223856 (14%)]\tLoss: 0.385606\n",
      "Train Epoch: 7 [64000/223856 (29%)]\tLoss: 0.149012\n",
      "Train Epoch: 7 [96000/223856 (43%)]\tLoss: 0.393371\n",
      "Train Epoch: 7 [128000/223856 (57%)]\tLoss: 0.241360\n",
      "Train Epoch: 7 [160000/223856 (71%)]\tLoss: 0.462409\n",
      "Train Epoch: 7 [192000/223856 (86%)]\tLoss: 0.354618\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 8 [0/223856 (0%)]\tLoss: 0.298688\n",
      "Train Epoch: 8 [32000/223856 (14%)]\tLoss: 0.152455\n",
      "Train Epoch: 8 [64000/223856 (29%)]\tLoss: 0.244408\n",
      "Train Epoch: 8 [96000/223856 (43%)]\tLoss: 0.078499\n",
      "Train Epoch: 8 [128000/223856 (57%)]\tLoss: 0.153814\n",
      "Train Epoch: 8 [160000/223856 (71%)]\tLoss: 0.241730\n",
      "Train Epoch: 8 [192000/223856 (86%)]\tLoss: 0.377553\n",
      "\n",
      "Training set: Accuracy: 204700/223856 (91%)\n",
      "Test set: Accuracy: 87778/95939 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/223856 (0%)]\tLoss: 0.159966\n",
      "Train Epoch: 9 [32000/223856 (14%)]\tLoss: 0.281964\n",
      "Train Epoch: 9 [64000/223856 (29%)]\tLoss: 0.242223\n",
      "Train Epoch: 9 [96000/223856 (43%)]\tLoss: 0.214790\n",
      "Train Epoch: 9 [128000/223856 (57%)]\tLoss: 0.179357\n",
      "Train Epoch: 9 [160000/223856 (71%)]\tLoss: 0.197916\n",
      "Train Epoch: 9 [192000/223856 (86%)]\tLoss: 0.182939\n",
      "\n",
      "Training set: Accuracy: 204731/223856 (91%)\n",
      "Test set: Accuracy: 87789/95939 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = Model()\n",
    "HD_pred = training(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f141715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/223856 (0%)]\tLoss: 0.685913\n",
      "Train Epoch: 0 [32000/223856 (14%)]\tLoss: 0.271475\n",
      "Train Epoch: 0 [64000/223856 (29%)]\tLoss: 0.317150\n",
      "Train Epoch: 0 [96000/223856 (43%)]\tLoss: 0.357402\n",
      "Train Epoch: 0 [128000/223856 (57%)]\tLoss: 0.235426\n",
      "Train Epoch: 0 [160000/223856 (71%)]\tLoss: 0.350099\n",
      "Train Epoch: 0 [192000/223856 (86%)]\tLoss: 0.381706\n",
      "\n",
      "Training set: Accuracy: 204503/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 1 [0/223856 (0%)]\tLoss: 0.163584\n",
      "Train Epoch: 1 [32000/223856 (14%)]\tLoss: 0.315957\n",
      "Train Epoch: 1 [64000/223856 (29%)]\tLoss: 0.199576\n",
      "Train Epoch: 1 [96000/223856 (43%)]\tLoss: 0.352845\n",
      "Train Epoch: 1 [128000/223856 (57%)]\tLoss: 0.356115\n",
      "Train Epoch: 1 [160000/223856 (71%)]\tLoss: 0.421588\n",
      "Train Epoch: 1 [192000/223856 (86%)]\tLoss: 0.310282\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/223856 (0%)]\tLoss: 0.349585\n",
      "Train Epoch: 2 [32000/223856 (14%)]\tLoss: 0.347914\n",
      "Train Epoch: 2 [64000/223856 (29%)]\tLoss: 0.389075\n",
      "Train Epoch: 2 [96000/223856 (43%)]\tLoss: 0.239657\n",
      "Train Epoch: 2 [128000/223856 (57%)]\tLoss: 0.235107\n",
      "Train Epoch: 2 [160000/223856 (71%)]\tLoss: 0.241020\n",
      "Train Epoch: 2 [192000/223856 (86%)]\tLoss: 0.276426\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/223856 (0%)]\tLoss: 0.423207\n",
      "Train Epoch: 3 [32000/223856 (14%)]\tLoss: 0.315526\n",
      "Train Epoch: 3 [64000/223856 (29%)]\tLoss: 0.127138\n",
      "Train Epoch: 3 [96000/223856 (43%)]\tLoss: 0.195158\n",
      "Train Epoch: 3 [128000/223856 (57%)]\tLoss: 0.400359\n",
      "Train Epoch: 3 [160000/223856 (71%)]\tLoss: 0.271950\n",
      "Train Epoch: 3 [192000/223856 (86%)]\tLoss: 0.197848\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 4 [0/223856 (0%)]\tLoss: 0.277794\n",
      "Train Epoch: 4 [32000/223856 (14%)]\tLoss: 0.201487\n",
      "Train Epoch: 4 [64000/223856 (29%)]\tLoss: 0.199026\n",
      "Train Epoch: 4 [96000/223856 (43%)]\tLoss: 0.573850\n",
      "Train Epoch: 4 [128000/223856 (57%)]\tLoss: 0.273220\n",
      "Train Epoch: 4 [160000/223856 (71%)]\tLoss: 0.202462\n",
      "Train Epoch: 4 [192000/223856 (86%)]\tLoss: 0.387187\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 5 [0/223856 (0%)]\tLoss: 0.234591\n",
      "Train Epoch: 5 [32000/223856 (14%)]\tLoss: 0.200261\n",
      "Train Epoch: 5 [64000/223856 (29%)]\tLoss: 0.162904\n",
      "Train Epoch: 5 [96000/223856 (43%)]\tLoss: 0.352712\n",
      "Train Epoch: 5 [128000/223856 (57%)]\tLoss: 0.344549\n",
      "Train Epoch: 5 [160000/223856 (71%)]\tLoss: 0.161396\n",
      "Train Epoch: 5 [192000/223856 (86%)]\tLoss: 0.348656\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 6 [0/223856 (0%)]\tLoss: 0.350531\n",
      "Train Epoch: 6 [32000/223856 (14%)]\tLoss: 0.162773\n",
      "Train Epoch: 6 [64000/223856 (29%)]\tLoss: 0.240571\n",
      "Train Epoch: 6 [96000/223856 (43%)]\tLoss: 0.379034\n",
      "Train Epoch: 6 [128000/223856 (57%)]\tLoss: 0.530793\n",
      "Train Epoch: 6 [160000/223856 (71%)]\tLoss: 0.126784\n",
      "Train Epoch: 6 [192000/223856 (86%)]\tLoss: 0.389361\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 7 [0/223856 (0%)]\tLoss: 0.284178\n",
      "Train Epoch: 7 [32000/223856 (14%)]\tLoss: 0.347817\n",
      "Train Epoch: 7 [64000/223856 (29%)]\tLoss: 0.240152\n",
      "Train Epoch: 7 [96000/223856 (43%)]\tLoss: 0.239013\n",
      "Train Epoch: 7 [128000/223856 (57%)]\tLoss: 0.274666\n",
      "Train Epoch: 7 [160000/223856 (71%)]\tLoss: 0.309558\n",
      "Train Epoch: 7 [192000/223856 (86%)]\tLoss: 0.345131\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 8 [0/223856 (0%)]\tLoss: 0.423088\n",
      "Train Epoch: 8 [32000/223856 (14%)]\tLoss: 0.424630\n",
      "Train Epoch: 8 [64000/223856 (29%)]\tLoss: 0.315140\n",
      "Train Epoch: 8 [96000/223856 (43%)]\tLoss: 0.167696\n",
      "Train Epoch: 8 [128000/223856 (57%)]\tLoss: 0.125475\n",
      "Train Epoch: 8 [160000/223856 (71%)]\tLoss: 0.310350\n",
      "Train Epoch: 8 [192000/223856 (86%)]\tLoss: 0.427084\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/223856 (0%)]\tLoss: 0.273268\n",
      "Train Epoch: 9 [32000/223856 (14%)]\tLoss: 0.202772\n",
      "Train Epoch: 9 [64000/223856 (29%)]\tLoss: 0.239401\n",
      "Train Epoch: 9 [96000/223856 (43%)]\tLoss: 0.310069\n",
      "Train Epoch: 9 [128000/223856 (57%)]\tLoss: 0.344180\n",
      "Train Epoch: 9 [160000/223856 (71%)]\tLoss: 0.204027\n",
      "Train Epoch: 9 [192000/223856 (86%)]\tLoss: 0.340818\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network_bn_do = Model_bn_do()\n",
    "HD_pred_bn_do = training(network_bn_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f44da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_xavier(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "def init_kaiming(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f133e008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=17, out_features=17, bias=True)\n",
       "  (fc2): Linear(in_features=17, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_xavier = Model()\n",
    "network_xavier.apply(init_xavier)\n",
    "\n",
    "network_kaiming = Model()\n",
    "network_kaiming.apply(init_kaiming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3fafddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/223856 (0%)]\tLoss: 0.974191\n",
      "Train Epoch: 0 [32000/223856 (14%)]\tLoss: 0.372473\n",
      "Train Epoch: 0 [64000/223856 (29%)]\tLoss: 0.298826\n",
      "Train Epoch: 0 [96000/223856 (43%)]\tLoss: 0.233491\n",
      "Train Epoch: 0 [128000/223856 (57%)]\tLoss: 0.215461\n",
      "Train Epoch: 0 [160000/223856 (71%)]\tLoss: 0.237739\n",
      "Train Epoch: 0 [192000/223856 (86%)]\tLoss: 0.258835\n",
      "\n",
      "Training set: Accuracy: 204613/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 1 [0/223856 (0%)]\tLoss: 0.325696\n",
      "Train Epoch: 1 [32000/223856 (14%)]\tLoss: 0.274143\n",
      "Train Epoch: 1 [64000/223856 (29%)]\tLoss: 0.235802\n",
      "Train Epoch: 1 [96000/223856 (43%)]\tLoss: 0.240224\n",
      "Train Epoch: 1 [128000/223856 (57%)]\tLoss: 0.227027\n",
      "Train Epoch: 1 [160000/223856 (71%)]\tLoss: 0.259625\n",
      "Train Epoch: 1 [192000/223856 (86%)]\tLoss: 0.231133\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/223856 (0%)]\tLoss: 0.326677\n",
      "Train Epoch: 2 [32000/223856 (14%)]\tLoss: 0.302245\n",
      "Train Epoch: 2 [64000/223856 (29%)]\tLoss: 0.276923\n",
      "Train Epoch: 2 [96000/223856 (43%)]\tLoss: 0.221529\n",
      "Train Epoch: 2 [128000/223856 (57%)]\tLoss: 0.220133\n",
      "Train Epoch: 2 [160000/223856 (71%)]\tLoss: 0.292628\n",
      "Train Epoch: 2 [192000/223856 (86%)]\tLoss: 0.139491\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/223856 (0%)]\tLoss: 0.194227\n",
      "Train Epoch: 3 [32000/223856 (14%)]\tLoss: 0.185884\n",
      "Train Epoch: 3 [64000/223856 (29%)]\tLoss: 0.303698\n",
      "Train Epoch: 3 [96000/223856 (43%)]\tLoss: 0.301798\n",
      "Train Epoch: 3 [128000/223856 (57%)]\tLoss: 0.266210\n",
      "Train Epoch: 3 [160000/223856 (71%)]\tLoss: 0.262134\n",
      "Train Epoch: 3 [192000/223856 (86%)]\tLoss: 0.299098\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 4 [0/223856 (0%)]\tLoss: 0.128934\n",
      "Train Epoch: 4 [32000/223856 (14%)]\tLoss: 0.218852\n",
      "Train Epoch: 4 [64000/223856 (29%)]\tLoss: 0.219738\n",
      "Train Epoch: 4 [96000/223856 (43%)]\tLoss: 0.244151\n",
      "Train Epoch: 4 [128000/223856 (57%)]\tLoss: 0.315412\n",
      "Train Epoch: 4 [160000/223856 (71%)]\tLoss: 0.117996\n",
      "Train Epoch: 4 [192000/223856 (86%)]\tLoss: 0.319917\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 5 [0/223856 (0%)]\tLoss: 0.216664\n",
      "Train Epoch: 5 [32000/223856 (14%)]\tLoss: 0.233282\n",
      "Train Epoch: 5 [64000/223856 (29%)]\tLoss: 0.322862\n",
      "Train Epoch: 5 [96000/223856 (43%)]\tLoss: 0.327727\n",
      "Train Epoch: 5 [128000/223856 (57%)]\tLoss: 0.342692\n",
      "Train Epoch: 5 [160000/223856 (71%)]\tLoss: 0.283961\n",
      "Train Epoch: 5 [192000/223856 (86%)]\tLoss: 0.171351\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 6 [0/223856 (0%)]\tLoss: 0.238703\n",
      "Train Epoch: 6 [32000/223856 (14%)]\tLoss: 0.357783\n",
      "Train Epoch: 6 [64000/223856 (29%)]\tLoss: 0.362395\n",
      "Train Epoch: 6 [96000/223856 (43%)]\tLoss: 0.304918\n",
      "Train Epoch: 6 [128000/223856 (57%)]\tLoss: 0.312579\n",
      "Train Epoch: 6 [160000/223856 (71%)]\tLoss: 0.236067\n",
      "Train Epoch: 6 [192000/223856 (86%)]\tLoss: 0.131728\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 7 [0/223856 (0%)]\tLoss: 0.166883\n",
      "Train Epoch: 7 [32000/223856 (14%)]\tLoss: 0.291946\n",
      "Train Epoch: 7 [64000/223856 (29%)]\tLoss: 0.287890\n",
      "Train Epoch: 7 [96000/223856 (43%)]\tLoss: 0.261351\n",
      "Train Epoch: 7 [128000/223856 (57%)]\tLoss: 0.239646\n",
      "Train Epoch: 7 [160000/223856 (71%)]\tLoss: 0.191264\n",
      "Train Epoch: 7 [192000/223856 (86%)]\tLoss: 0.284654\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 8 [0/223856 (0%)]\tLoss: 0.267107\n",
      "Train Epoch: 8 [32000/223856 (14%)]\tLoss: 0.267543\n",
      "Train Epoch: 8 [64000/223856 (29%)]\tLoss: 0.285158\n",
      "Train Epoch: 8 [96000/223856 (43%)]\tLoss: 0.304677\n",
      "Train Epoch: 8 [128000/223856 (57%)]\tLoss: 0.319426\n",
      "Train Epoch: 8 [160000/223856 (71%)]\tLoss: 0.297478\n",
      "Train Epoch: 8 [192000/223856 (86%)]\tLoss: 0.248298\n",
      "\n",
      "Training set: Accuracy: 204668/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/223856 (0%)]\tLoss: 0.085851\n",
      "Train Epoch: 9 [32000/223856 (14%)]\tLoss: 0.363344\n",
      "Train Epoch: 9 [64000/223856 (29%)]\tLoss: 0.260326\n",
      "Train Epoch: 9 [96000/223856 (43%)]\tLoss: 0.237395\n",
      "Train Epoch: 9 [128000/223856 (57%)]\tLoss: 0.232701\n",
      "Train Epoch: 9 [160000/223856 (71%)]\tLoss: 0.314334\n",
      "Train Epoch: 9 [192000/223856 (86%)]\tLoss: 0.219238\n",
      "\n",
      "Training set: Accuracy: 204667/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HD_pred_xavier = training(network_xavier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "90b8327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/223856 (0%)]\tLoss: 0.585146\n",
      "Train Epoch: 0 [32000/223856 (14%)]\tLoss: 0.304574\n",
      "Train Epoch: 0 [64000/223856 (29%)]\tLoss: 0.259055\n",
      "Train Epoch: 0 [96000/223856 (43%)]\tLoss: 0.276775\n",
      "Train Epoch: 0 [128000/223856 (57%)]\tLoss: 0.211931\n",
      "Train Epoch: 0 [160000/223856 (71%)]\tLoss: 0.271027\n",
      "Train Epoch: 0 [192000/223856 (86%)]\tLoss: 0.243020\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 1 [0/223856 (0%)]\tLoss: 0.347468\n",
      "Train Epoch: 1 [32000/223856 (14%)]\tLoss: 0.239398\n",
      "Train Epoch: 1 [64000/223856 (29%)]\tLoss: 0.265410\n",
      "Train Epoch: 1 [96000/223856 (43%)]\tLoss: 0.158067\n",
      "Train Epoch: 1 [128000/223856 (57%)]\tLoss: 0.191635\n",
      "Train Epoch: 1 [160000/223856 (71%)]\tLoss: 0.398191\n",
      "Train Epoch: 1 [192000/223856 (86%)]\tLoss: 0.287094\n",
      "\n",
      "Training set: Accuracy: 204669/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/223856 (0%)]\tLoss: 0.174181\n",
      "Train Epoch: 2 [32000/223856 (14%)]\tLoss: 0.326252\n",
      "Train Epoch: 2 [64000/223856 (29%)]\tLoss: 0.306612\n",
      "Train Epoch: 2 [96000/223856 (43%)]\tLoss: 0.194281\n",
      "Train Epoch: 2 [128000/223856 (57%)]\tLoss: 0.257107\n",
      "Train Epoch: 2 [160000/223856 (71%)]\tLoss: 0.458024\n",
      "Train Epoch: 2 [192000/223856 (86%)]\tLoss: 0.277652\n",
      "\n",
      "Training set: Accuracy: 204663/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 3 [0/223856 (0%)]\tLoss: 0.313414\n",
      "Train Epoch: 3 [32000/223856 (14%)]\tLoss: 0.254209\n",
      "Train Epoch: 3 [64000/223856 (29%)]\tLoss: 0.198877\n",
      "Train Epoch: 3 [96000/223856 (43%)]\tLoss: 0.257517\n",
      "Train Epoch: 3 [128000/223856 (57%)]\tLoss: 0.179088\n",
      "Train Epoch: 3 [160000/223856 (71%)]\tLoss: 0.207246\n",
      "Train Epoch: 3 [192000/223856 (86%)]\tLoss: 0.322065\n",
      "\n",
      "Training set: Accuracy: 204650/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 4 [0/223856 (0%)]\tLoss: 0.416660\n",
      "Train Epoch: 4 [32000/223856 (14%)]\tLoss: 0.229029\n",
      "Train Epoch: 4 [64000/223856 (29%)]\tLoss: 0.257774\n",
      "Train Epoch: 4 [96000/223856 (43%)]\tLoss: 0.252524\n",
      "Train Epoch: 4 [128000/223856 (57%)]\tLoss: 0.352995\n",
      "Train Epoch: 4 [160000/223856 (71%)]\tLoss: 0.299012\n",
      "Train Epoch: 4 [192000/223856 (86%)]\tLoss: 0.402416\n",
      "\n",
      "Training set: Accuracy: 204661/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 5 [0/223856 (0%)]\tLoss: 0.245469\n",
      "Train Epoch: 5 [32000/223856 (14%)]\tLoss: 0.279612\n",
      "Train Epoch: 5 [64000/223856 (29%)]\tLoss: 0.185716\n",
      "Train Epoch: 5 [96000/223856 (43%)]\tLoss: 0.188634\n",
      "Train Epoch: 5 [128000/223856 (57%)]\tLoss: 0.417576\n",
      "Train Epoch: 5 [160000/223856 (71%)]\tLoss: 0.251227\n",
      "Train Epoch: 5 [192000/223856 (86%)]\tLoss: 0.110965\n",
      "\n",
      "Training set: Accuracy: 204673/223856 (91%)\n",
      "Test set: Accuracy: 87756/95939 (91%)\n",
      "\n",
      "Train Epoch: 6 [0/223856 (0%)]\tLoss: 0.290540\n",
      "Train Epoch: 6 [32000/223856 (14%)]\tLoss: 0.198952\n",
      "Train Epoch: 6 [64000/223856 (29%)]\tLoss: 0.202815\n",
      "Train Epoch: 6 [96000/223856 (43%)]\tLoss: 0.222043\n",
      "Train Epoch: 6 [128000/223856 (57%)]\tLoss: 0.191651\n",
      "Train Epoch: 6 [160000/223856 (71%)]\tLoss: 0.181968\n",
      "Train Epoch: 6 [192000/223856 (86%)]\tLoss: 0.325515\n",
      "\n",
      "Training set: Accuracy: 204655/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 7 [0/223856 (0%)]\tLoss: 0.229886\n",
      "Train Epoch: 7 [32000/223856 (14%)]\tLoss: 0.283276\n",
      "Train Epoch: 7 [64000/223856 (29%)]\tLoss: 0.367144\n",
      "Train Epoch: 7 [96000/223856 (43%)]\tLoss: 0.193659\n",
      "Train Epoch: 7 [128000/223856 (57%)]\tLoss: 0.272832\n",
      "Train Epoch: 7 [160000/223856 (71%)]\tLoss: 0.205770\n",
      "Train Epoch: 7 [192000/223856 (86%)]\tLoss: 0.250384\n",
      "\n",
      "Training set: Accuracy: 204664/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 8 [0/223856 (0%)]\tLoss: 0.172346\n",
      "Train Epoch: 8 [32000/223856 (14%)]\tLoss: 0.133085\n",
      "Train Epoch: 8 [64000/223856 (29%)]\tLoss: 0.289585\n",
      "Train Epoch: 8 [96000/223856 (43%)]\tLoss: 0.181045\n",
      "Train Epoch: 8 [128000/223856 (57%)]\tLoss: 0.245863\n",
      "Train Epoch: 8 [160000/223856 (71%)]\tLoss: 0.144481\n",
      "Train Epoch: 8 [192000/223856 (86%)]\tLoss: 0.237620\n",
      "\n",
      "Training set: Accuracy: 204661/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/223856 (0%)]\tLoss: 0.224212\n",
      "Train Epoch: 9 [32000/223856 (14%)]\tLoss: 0.339979\n",
      "Train Epoch: 9 [64000/223856 (29%)]\tLoss: 0.161790\n",
      "Train Epoch: 9 [96000/223856 (43%)]\tLoss: 0.413234\n",
      "Train Epoch: 9 [128000/223856 (57%)]\tLoss: 0.298512\n",
      "Train Epoch: 9 [160000/223856 (71%)]\tLoss: 0.278382\n",
      "Train Epoch: 9 [192000/223856 (86%)]\tLoss: 0.119053\n",
      "\n",
      "Training set: Accuracy: 204673/223856 (91%)\n",
      "Test set: Accuracy: 87753/95939 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HD_pred_kaiming = training(network_kaiming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71405834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.fc1 = nn.Linear(17,17)\n",
    "        self.fc2 = nn.Linear(17,2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #1\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #2\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #3\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #4\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #5\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #6\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #7\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #8\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #9\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #10\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #11\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        #12\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "444ce994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "network1 = Model2()\n",
    "PATH = \"C:/Users/JinnyeongHeo/Desktop/2022-1/추천시스템/HeartDisease_model/NetModel.pth\" \n",
    "network1.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8100cb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26.61  0.    0.    0.    0.    0.    0.    0.    9.    5.    0.    1.\n",
      "   2.   12.    1.    0.    0.  ]\n",
      " [31.09  0.    0.    0.    2.    0.    0.    0.    9.    5.    0.    1.\n",
      "   4.    7.    0.    0.    0.  ]]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "print(input_np[50:52])\n",
    "print(label_np[50:52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "848b41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.Tensor(input_data_hdy[10000:10020].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adea9965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7487, 0.2513],\n",
      "        [0.7856, 0.2144],\n",
      "        [0.7888, 0.2112],\n",
      "        [0.7420, 0.2580],\n",
      "        [0.5819, 0.4181],\n",
      "        [0.8313, 0.1687],\n",
      "        [0.6979, 0.3021],\n",
      "        [0.7180, 0.2820],\n",
      "        [0.9040, 0.0960],\n",
      "        [0.5568, 0.4432],\n",
      "        [0.9545, 0.0455],\n",
      "        [0.8314, 0.1686],\n",
      "        [0.5858, 0.4142],\n",
      "        [0.9565, 0.0435],\n",
      "        [0.7709, 0.2291],\n",
      "        [0.9540, 0.0460],\n",
      "        [0.8081, 0.1919],\n",
      "        [0.9665, 0.0335],\n",
      "        [0.7864, 0.2136],\n",
      "        [0.8232, 0.1768]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7487, 0.2513],\n",
       "        [0.7856, 0.2144],\n",
       "        [0.7888, 0.2112],\n",
       "        [0.7420, 0.2580],\n",
       "        [0.5819, 0.4181],\n",
       "        [0.8313, 0.1687],\n",
       "        [0.6979, 0.3021],\n",
       "        [0.7180, 0.2820],\n",
       "        [0.9040, 0.0960],\n",
       "        [0.5568, 0.4432],\n",
       "        [0.9545, 0.0455],\n",
       "        [0.8314, 0.1686],\n",
       "        [0.5858, 0.4142],\n",
       "        [0.9565, 0.0435],\n",
       "        [0.7709, 0.2291],\n",
       "        [0.9540, 0.0460],\n",
       "        [0.8081, 0.1919],\n",
       "        [0.9665, 0.0335],\n",
       "        [0.7864, 0.2136],\n",
       "        [0.8232, 0.1768]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_exercise(c,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d048f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.Tensor(input_data_hdn[10000:10020].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f95afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9744, 0.0257],\n",
      "        [0.9574, 0.0426],\n",
      "        [0.9739, 0.0261],\n",
      "        [0.9965, 0.0035],\n",
      "        [0.8071, 0.1929],\n",
      "        [0.9595, 0.0405],\n",
      "        [0.9618, 0.0382],\n",
      "        [0.9882, 0.0118],\n",
      "        [0.8761, 0.1239],\n",
      "        [0.9933, 0.0067],\n",
      "        [0.9759, 0.0241],\n",
      "        [0.9945, 0.0055],\n",
      "        [0.9079, 0.0921],\n",
      "        [0.9759, 0.0241],\n",
      "        [0.9750, 0.0250],\n",
      "        [0.9668, 0.0332],\n",
      "        [0.9568, 0.0432],\n",
      "        [0.9623, 0.0377],\n",
      "        [0.9919, 0.0081],\n",
      "        [0.9269, 0.0731]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9744, 0.0257],\n",
       "        [0.9574, 0.0426],\n",
       "        [0.9739, 0.0261],\n",
       "        [0.9965, 0.0035],\n",
       "        [0.8071, 0.1929],\n",
       "        [0.9595, 0.0405],\n",
       "        [0.9618, 0.0382],\n",
       "        [0.9882, 0.0118],\n",
       "        [0.8761, 0.1239],\n",
       "        [0.9933, 0.0067],\n",
       "        [0.9759, 0.0241],\n",
       "        [0.9945, 0.0055],\n",
       "        [0.9079, 0.0921],\n",
       "        [0.9759, 0.0241],\n",
       "        [0.9750, 0.0250],\n",
       "        [0.9668, 0.0332],\n",
       "        [0.9568, 0.0432],\n",
       "        [0.9623, 0.0377],\n",
       "        [0.9919, 0.0081],\n",
       "        [0.9269, 0.0731]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_exercise(d,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a720d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[23.6500,  1.0000,  0.0000,  0.0000, 30.0000,  5.0000,  1.0000,  1.0000,\n",
      "         10.0000,  5.0000,  2.0000,  0.0000,  3.0000,  8.0000,  0.0000,  0.0000,\n",
      "          1.0000]])\n",
      "tensor([[0.5819, 0.4181]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5819, 0.4181]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = torch.Tensor(input_data_hdy[10004:10005].values)\n",
    "print(tmp1)\n",
    "practice_exercise(tmp1,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da28820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22.,  0.,  0.,  0.,  0.,  5.,  0.,  0.,  3.,  3.,  0., 10.,  2.,  7.,\n",
      "          0.,  0.,  0.]])\n",
      "tensor([[0.9948, 0.0052]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9948, 0.0052]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jinnyeong = torch.Tensor([[22.0000,  0.0000,  0.0000,  0.0000, 0.0000,  5.0000,  0.0000,  0.0000,\n",
    "         3.0000,  3.0000,  0.0000,  10.0000,  2.0000,  7.0000,  0.0000,  0.0000,\n",
    "          0.0000]])\n",
    "print(Jinnyeong)\n",
    "practice_exercise(Jinnyeong,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d21d42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[20.4400,  0.0000,  1.0000,  0.0000,  0.0000,  3.0000,  0.0000,  1.0000,\n",
      "          2.0000,  3.0000,  0.0000,  1.0000,  4.0000,  8.0000,  0.0000,  0.0000,\n",
      "          0.0000]])\n",
      "tensor([[0.9946, 0.0054]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9946, 0.0054]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chanju = torch.Tensor([[20.4400,  0.0000,  1.0000,  0.0000,  0.0000,  3.0000,  0.0000,  1.0000,\n",
    "                        2.0000,  3.0000,  0.0000,  1.0000,  4.0000,  8.0000,  0.0000,  0.0000, \n",
    "                        0.0000]])\n",
    "print(Chanju)\n",
    "practice_exercise(Chanju,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd962f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29.4000,  0.0000,  0.0000,  0.0000,  4.0000,  4.0000,  0.0000,  0.0000,\n",
      "          3.0000,  5.0000,  0.0000,  1.0000,  4.0000,  8.0000,  1.0000,  0.0000,\n",
      "          0.0000]])\n",
      "tensor([[0.9942, 0.0058]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9942, 0.0058]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jaehyuk = torch.Tensor([[29.4000,  0.0000,  0.0000,  0.0000,  4.0000, 4.0000,  0.0000,  0.0000,    \n",
    "                      3.0000,  5.00000,  0.0000,  1.0000,  4.0000,  8.0000,  1.0000,   0.0000,   \n",
    "                      0.0000]])\n",
    "print(Jaehyuk)\n",
    "practice_exercise(Jaehyuk,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0aa6add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30.0600,  1.0000,  1.0000,  0.0000, 20.0000, 30.0000,  0.0000,  0.0000,\n",
      "          3.0000,  0.0000,  0.0000,  1.0000,  2.0000,  8.0000,  0.0000,  0.0000,\n",
      "          0.0000]])\n",
      "tensor([[0.9678, 0.0322]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9678, 0.0322]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dongchan = torch.Tensor([[30.0600, 1.0000,  1.0000,  0.0000,  20.0000, 30.0000,  0.0000, 0.0000,\n",
    "                          3.0000,  0.0000,  0.0000,  1.0000,  2.0000,  8.0000,  0.0000,  0.0000, \n",
    "                          0.0000]])\n",
    "print(Dongchan)\n",
    "practice_exercise(Dongchan,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ab6e6f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24.9700,  1.0000,  0.0000,  1.0000, 30.0000,  0.0000,  0.0000,  1.0000,\n",
      "          8.0000,  2.0000,  0.0000,  1.0000,  2.0000, 14.0000,  0.0000,  0.0000,\n",
      "          0.0000]])\n",
      "tensor([[0.8672, 0.1328]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8672, 0.1328]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp3 = torch.Tensor(input_data_hdy[10554:10555].values)\n",
    "print(tmp3)\n",
    "practice_exercise(tmp3,network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d900a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24.9700,  0.0000,  0.0000,  1.0000, 30.0000,  0.0000,  0.0000,  1.0000,\n",
      "          8.0000,  2.0000,  0.0000,  1.0000,  2.0000, 14.0000,  0.0000,  0.0000,\n",
      "          0.0000]])\n",
      "tensor([[0.8851, 0.1149]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8851, 0.1149]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp3_1 = torch.Tensor([[24.9700,  0.0000,  0.0000,  1.0000, 30.0000,  0.0000,  0.0000,  1.0000,\n",
    "          8.0000,  2.0000,  0.0000,  1.0000,  2.0000, 14.0000,  0.0000,  0.0000,\n",
    "          0.0000]])\n",
    "print(tmp3_1)\n",
    "practice_exercise(tmp3_1,network1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
